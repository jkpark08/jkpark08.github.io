---
layout: post
title: A 3D Scene-Based Dataset for Realistic Image Deblurring. NeurIPS, 2024.
date: 2024-09-29 13:32:20 +0300
description: NeurIPS, 2024. # Add post description (optional)
img: gsblur.JPG # Add image post (optional)
fig-caption: # Add figcaption (optional)
tags: [3DGS, Dataset, Deblurring] #
---
##### Dongwoo Lee, Joonkyu Park, and Kyoung Mu Lee.

To train a deblurring network, an appropriate dataset with paired blurry and sharp images is essential.Existing datasets collect blurry images either synthetically by aggregating consecutive sharp frames or using sophisticated camera systems to capture real blur.
However, these methods offer limited diversity in blur types (blur trajectories) or require extensive human effort to reconstruct large-scale datasets, failing to fully reflect real-world blur scenarios.
To address this, we propose GS-Blur, a dataset of synthesized realistic blurry images created using a novel approach. To this end, we first reconstruct 3D scenes from multi-view images using 3D Gaussian Splatting~(3DGS), then render blurry images by moving the camera view along the randomly generated motion trajectories.
By adopting various camera trajectories in reconstructing our GS-Blur, our dataset contains realistic and diverse types of blur, offering a large-scale dataset that generalizes well to real-world blur.
Using GS-Blur with various deblurring methods, we demonstrate its ability to generalize effectively compared to previous synthetic or real blur datasets, showing significant improvements in deblurring performance. [[paper](https://arxiv.org/pdf/2410.23658)] 
